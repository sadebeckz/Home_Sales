# Home Sales Analysis - SparkSQL Challenge

This project uses PySpark and SparkSQL to analyze a home sales dataset. Key tasks include:

- Reading CSV data from an AWS S3 bucket
- Creating temporary views and running SQL queries
- Caching and uncaching tables
- Partitioning data and working with Parquet files
- Comparing runtimes for different storage/query methods

## File

- `Home_Sales.ipynb` â€“ Contains the full analysis and results

## Data Source

- CSV file from AWS S3 bucket (provided by edX Boot Camp)

> If any code was sourced externally or completed in collaboration, it is noted within the notebook.
